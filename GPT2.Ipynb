{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Load GPT2 model and add layer at each block for each layer.\n",
    "\n",
    "import torch\n",
    "from transformers import GPT2Model\n",
    "\n",
    "class TransformerLayer(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.expand_A = nn.Linear(config.n_embd, 2048, bias=False)\n",
    "        self.attn_weight_transform = nn.Linear(2304, 4096, bias=False)\n",
    "        self.attn_bias = nn.Parameter(torch.zeros(4096))\n",
    "        self.proj_weight_transform = nn.Linear(768, 2048, bias=False)\n",
    "        self.proj_bias = nn.Parameter(torch.zeros(2048))\n",
    "        self.mlp_fc_transform = nn.Linear(3072, 2048, bias=False)\n",
    "        self.mlp_proj_transform = nn.Linear(2048, 2048, bias=False)\n",
    "        self.ln1_weight = nn.Parameter(torch.ones(2048))\n",
    "        self.ln1_bias = nn.Parameter(torch.zeros(2048))\n",
    "        self.ln2_weight = nn.Parameter(torch.ones(2048))\n",
    "        self.ln2_bias = nn.Parameter(torch.zeros(2048))\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Simulate some computations\n",
    "        return x\n",
    "\n",
    "class CustomGPT2(nn.Module):\n",
    "    def __init__(self, model_name='gpt2'):\n",
    "        super().__init__()\n",
    "        self.base_model = GPT2Model.from_pretrained(model_name)\n",
    "        for param in self.base_model.parameters():\n",
    "            param.requires_grad = False  # Freeze all original GPT-2 parameters\n",
    "        self.custom_layers = nn.ModuleList([TransformerLayer(self.base_model.config) for _ in self.base_model.h])\n",
    "\n",
    "    def forward(self, input_ids, attention_mask=None):\n",
    "        last_hidden_state = self.base_model(input_ids=input_ids, attention_mask=attention_mask).last_hidden_state\n",
    "        for layer in self.custom_layers:\n",
    "            last_hidden_state = layer(last_hidden_state)\n",
    "        return last_hidden_state\n",
    "\n",
    "# Initialize the custom model\n",
    "model = CustomGPT2()\n",
    "\n",
    "# Print trainable parameters\n",
    "print(\"Trainable Parameters:\")\n",
    "for name, param in model.named_parameters():\n",
    "    if param.requires_grad:\n",
    "        print(f\"{name}: {param.size()}\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
